# Real-Time Video CI/CD Workflow
#
# Overview:
# - Orchestrates a five-stage pipeline for dataset videos:
#   acquire (FTP sync) → validate (metadata) → compose (ffmpeg) → upload (Vimeo) → update (S3 dataset.json)
# - Uses a Zyra scheduler image (GHCR) with entrypoint overridden to run shell scripts.
#
# Usage:
# - Requires pipeline variable `DATASET_NAME` mapping to `datasets/<name>.env`.
# - Optional `ZYRA_SCHEDULER_IMAGE` to override the runtime image (defaults to GHCR latest).
#
# Paths & Artifacts:
# - Workspace-local data root: `${CI_PROJECT_DIR}/_work` for portability and artifact collection.
# - Frames: `_work/images/${DATASET_NAME}` (cached across pipelines by `${DATASET_NAME}-frames`).
# - Output video: `_work/output/${DATASET_NAME}.mp4`.
#
# Resilience:
# - Acquire and Vimeo upload have retry policies for transient network/API errors.
#
# ### *** Zyra *** ### | Powered by NOAA/GSL

workflow:
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
    - if: '$DATASET_NAME'
    - when: never

variables:
  # Default runtime image for Zyra scheduler jobs
  ZYRA_SCHEDULER_IMAGE: ghcr.io/noaa-gsl/zyra-scheduler:latest

default:
  before_script:
    - |
      # Load dataset-specific environment variables
      if [ ! -f "datasets/${DATASET_NAME}.env" ]; then
        echo "Missing datasets/${DATASET_NAME}.env" >&2
        exit 1
      fi
      . "datasets/${DATASET_NAME}.env"
      echo "Loaded dataset config: ${DATASET_NAME}"

      # Zyra logging verbosity control (valid: debug, info, quiet)
      export ZYRA_VERBOSITY="${ZYRA_VERBOSITY:-info}"
      case "${ZYRA_VERBOSITY}" in
        debug)
          export ZYRA_CLI_VERBOSE_FLAG="-v"
          ;;
        info|quiet)
          unset ZYRA_CLI_VERBOSE_FLAG
          ;;
        *)
          echo "Unknown ZYRA_VERBOSITY='${ZYRA_VERBOSITY}', defaulting to 'info'"
          export ZYRA_VERBOSITY="info"
          unset ZYRA_CLI_VERBOSE_FLAG
          ;;
      esac
      echo "Zyra verbosity: ${ZYRA_VERBOSITY}"

      # Print Zyra CLI version for visibility/branding
      zyra --version

      # Shell echoing now handled by Zyra when ZYRA_VERBOSITY=debug

      # Define working directories for frames, outputs, and artifacts
      export DATA_ROOT="${CI_PROJECT_DIR}/_work"
      export FRAMES_DIR="${DATA_ROOT}/images/${DATASET_NAME}"
      export OUTPUT_DIR="${DATA_ROOT}/output"
      export OUTPUT_PATH="${OUTPUT_DIR}/${DATASET_NAME}.mp4"

      # Create required directories
      mkdir -p "${FRAMES_DIR}" "${OUTPUT_DIR}"

stages:
  - acquire   # get raw images
  - validate  # check metadata + cadence
  - compose   # build MP4 video
  - upload    # push video to Vimeo
  - update    # update dataset.json in S3

# ----------------------------
# Stage 1: Acquire input frames
# ----------------------------
acquire-images:
  image:
    name: $ZYRA_SCHEDULER_IMAGE
    entrypoint: [""]
  stage: acquire
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
    - if: '$DATASET_NAME'
  retry:
    max: 2
    when:
      - script_failure
      - runner_system_failure
      - stuck_or_timeout_failure
  tags: [container, woc, sosx]
  cache:
    key: "${DATASET_NAME}-frames"
    paths:
      - _work/images/${DATASET_NAME}
    policy: pull-push
  script:
    - |
      # Sync new frames from FTP source to FRAMES_DIR
      set +e
      zyra ${ZYRA_CLI_VERBOSE_FLAG:-} acquire ftp \
        ftp://${FTP_HOST}${FTP_PATH} \
        --sync-dir "${FRAMES_DIR}" \
        --since-period ${SINCE_PERIOD} \
        --pattern "${PATTERN}" \
        --date-format "${DATE_FORMAT}"
      rc=$?
      set -e
      if [ $rc -ne 0 ]; then
        echo "Acquire exited with rc=$rc; checking for any downloaded frames before failing..."
      fi
      dl_count=$(find "${FRAMES_DIR}" -maxdepth 1 -type f \( -iname '*.png' -o -iname '*.jpg' -o -iname '*.jpeg' \) | wc -l)
      if [ "$dl_count" -gt 0 ]; then
        echo "Proceeding despite acquire errors; found ${dl_count} frames in ${FRAMES_DIR}."
      else
        echo "No frames downloaded; failing acquire step (rc=${rc})."
        exit ${rc}
      fi

      # Create a lightweight artifact: summary + small preview subset
      mkdir -p "${FRAMES_DIR}/metadata" "${FRAMES_DIR}/preview"
      {
        echo "dataset=${DATASET_NAME}"
        echo "frames_dir=${FRAMES_DIR}"
        echo "pattern=${PATTERN}"
        echo "since_period=${SINCE_PERIOD}"
        echo "date_format=${DATE_FORMAT}"
        echo -n "file_count="
        find "${FRAMES_DIR}" -maxdepth 1 -type f \( -iname '*.png' -o -iname '*.jpg' -o -iname '*.jpeg' \) | wc -l
        echo -n "dir_size="
        du -sh "${FRAMES_DIR}" 2>/dev/null | awk '{print $1}'
        echo "generated_at=$(date -u +%Y-%m-%dT%H:%M:%SZ)"
      } > "${FRAMES_DIR}/metadata/acquire-summary.txt"

      # Copy up to 6 most recent images into preview (by mtime)
      find "${FRAMES_DIR}" -maxdepth 1 -type f \( -iname '*.png' -o -iname '*.jpg' -o -iname '*.jpeg' \) -printf '%T@\t%p\n' \
        | sort -nr | head -n 6 | cut -f2- \
        | while IFS= read -r f; do cp -n "$f" "${FRAMES_DIR}/preview/"; done || true
  artifacts:
    expire_in: 1 week
    paths:
      - _work/images/${DATASET_NAME}/metadata/acquire-summary.txt
      - _work/images/${DATASET_NAME}/preview/

# --------------------------------------
# Stage 2: Validate frames and metadata
# --------------------------------------
validate-frames:
  image:
    name: $ZYRA_SCHEDULER_IMAGE
    entrypoint: [""]
  stage: validate
  needs: ["acquire-images"]
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
    - if: '$DATASET_NAME'
  tags: [container, woc, sosx]
  cache:
    key: "${DATASET_NAME}-frames"
    paths:
      - _work/images/${DATASET_NAME}
    policy: pull
  script:
    - |
      # Generate metadata.json from frames (cadence, timestamps)
      zyra ${ZYRA_CLI_VERBOSE_FLAG:-} transform metadata \
        --frames-dir "${FRAMES_DIR}" \
        --pattern "${PATTERN}" \
        --datetime-format "${DATE_FORMAT}" \
        --period-seconds ${PERIOD_SECONDS} \
        --output "${FRAMES_DIR}/metadata/frames-meta.json"
  artifacts:
    paths:
      - _work/images/${DATASET_NAME}/metadata/frames-meta.json
      - _work/images/${DATASET_NAME}/preview/

# --------------------------------------
# Stage 3: Compose frames into video MP4
# --------------------------------------
compose-video:
  image:
    name: $ZYRA_SCHEDULER_IMAGE
    entrypoint: [""]
  stage: compose
  needs: ["validate-frames"]
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
    - if: '$DATASET_NAME'
  tags: [container, woc, sosx]
  cache:
    key: "${DATASET_NAME}-frames"
    paths:
      - _work/images/${DATASET_NAME}
    policy: pull
  script:
    - |
      # Convert frames into MP4 animation (optionally with basemap)
      if [ -n "${BASEMAP_IMAGE:-}" ]; then
        echo "Using basemap: ${BASEMAP_IMAGE}"
        zyra ${ZYRA_CLI_VERBOSE_FLAG:-} visualize compose-video \
          --frames "${FRAMES_DIR}" \
          --output "${OUTPUT_PATH}" \
          --basemap "${BASEMAP_IMAGE}"
      else
        zyra ${ZYRA_CLI_VERBOSE_FLAG:-} visualize compose-video \
          --frames "${FRAMES_DIR}" \
          --output "${OUTPUT_PATH}"
      fi

      # Verify output video was actually produced and is non-empty
      if [ ! -s "${OUTPUT_PATH}" ]; then
        echo "Compose step succeeded but no video was generated at ${OUTPUT_PATH}" >&2
        exit 1
      fi

      # Optionally validate the MP4 with ffprobe if available
      if command -v ffprobe >/dev/null 2>&1; then
        if ! ffprobe -v error -select_streams v:0 -show_entries stream=codec_name -of csv=p=0 "${OUTPUT_PATH}" >/dev/null 2>&1; then
          echo "Generated video appears invalid or has no video stream: ${OUTPUT_PATH}" >&2
          exit 1
        fi
      fi
  artifacts:
    expire_in: 1 week
    paths:
      - _work/output/

# ----------------------------------------
# Stage 4: Upload rendered video to Vimeo
# ----------------------------------------
upload-vimeo:
  image:
    name: $ZYRA_SCHEDULER_IMAGE
    entrypoint: [""]
  stage: upload
  needs: ["compose-video", "validate-frames"]
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
    - if: '$DATASET_NAME'
  retry:
    max: 2
    when:
      - script_failure
  tags: [container, woc, sosx]
  cache:
    key: "${DATASET_NAME}-frames"
    paths:
      - _work/images/${DATASET_NAME}
    policy: pull
  script:
    - |
      # Replace Vimeo video with new MP4
      zyra ${ZYRA_CLI_VERBOSE_FLAG:-} decimate vimeo \
        --input "${OUTPUT_PATH}" \
        --replace-uri ${VIMEO_URI}

# ------------------------------------------------
# Stage 5: Update dataset.json in S3 with metadata
# ------------------------------------------------
update-metadata:
  image:
    name: $ZYRA_SCHEDULER_IMAGE
    entrypoint: [""]
  stage: update
  needs: ["validate-frames", "upload-vimeo"]
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
    - if: '$DATASET_NAME'
  tags: [container, woc, sosx]
  cache:
    key: "${DATASET_NAME}-frames"
    paths:
      - _work/images/${DATASET_NAME}
    policy: pull
  script:
    - |
      # Backup current dataset.json from S3 to local .bak
      zyra ${ZYRA_CLI_VERBOSE_FLAG:-} acquire s3 \
        --url ${S3_URL} \
        --output "${FRAMES_DIR}/metadata/dataset.json.bak"

      # Generate new dataset.json with Vimeo + frames metadata
      # Then overwrite original in S3
      zyra ${ZYRA_CLI_VERBOSE_FLAG:-} transform update-dataset-json \
        --input-url ${S3_URL} \
        --dataset-id ${DATASET_ID} \
        --meta "${FRAMES_DIR}/metadata/frames-meta.json" \
        --vimeo-uri ${VIMEO_URI} \
        --output - | zyra ${ZYRA_CLI_VERBOSE_FLAG:-} decimate s3 \
        --read-stdin \
        --url ${S3_URL}
  artifacts:
    paths:
      - _work/images/${DATASET_NAME}/metadata/dataset.json.bak
      - _work/images/${DATASET_NAME}/metadata/frames-meta.json
